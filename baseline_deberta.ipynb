{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline-deberta.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "background_execution": "on",
      "mount_file_id": "https://github.com/xiaoyufan/nbme/blob/main/baseline_deberta.ipynb",
      "authorship_tag": "ABX9TyNu8Z0Uw4ucLsE5gkFjaWZM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xiaoyufan/nbme/blob/main/baseline_deberta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NBME Baseline DeBERTa"
      ],
      "metadata": {
        "id": "XoauZTv1ekis"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configurations"
      ],
      "metadata": {
        "id": "jWPOFAMmescu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "  batch_size = 16\n",
        "  device = 'tpu'\n",
        "  epochs = 1\n",
        "  input_dir = '/content/drive/MyDrive/CS7150 Deep Learning Project/Dataset/Preprocessed'\n",
        "  mode = 'dev'\n",
        "  model = 'microsoft/deberta-base'\n",
        "  output_dir = '/content/drive/MyDrive/CS7150 Deep Learning Project/Dataset/Output'\n",
        "  sequence_max_length = 466"
      ],
      "metadata": {
        "id": "i2tVkqRCK-bn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Packages"
      ],
      "metadata": {
        "id": "8PAFcMWfep6h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fevyPYAS06FJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7d457a2-95d0-4178-a064-6ddbe603861f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.12.1)\n",
            "Collecting git+https://github.com/xiaoyufan/nbme.git\n",
            "  Cloning https://github.com/xiaoyufan/nbme.git to /tmp/pip-req-build-59zhv7b3\n",
            "  Running command git clone -q https://github.com/xiaoyufan/nbme.git /tmp/pip-req-build-59zhv7b3\n",
            "Building wheels for collected packages: nbme\n",
            "  Building wheel for nbme (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nbme: filename=nbme-1.0-py3-none-any.whl size=2308 sha256=1447d17552c3e0eb4e9c616cd51ff9b8714a1fa73fd89faf55560d1927c473f5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jgqau6pl/wheels/e2/dc/dd/b061e30220e414c0a096e4fbaddd405c1b526d1453d9a447e3\n",
            "Successfully built nbme\n",
            "Installing collected packages: nbme\n",
            "  Attempting uninstall: nbme\n",
            "    Found existing installation: nbme 1.0\n",
            "    Uninstalling nbme-1.0:\n",
            "      Successfully uninstalled nbme-1.0\n",
            "Successfully installed nbme-1.0\n",
            "Collecting torch-xla==1.11\n",
            "  Using cached https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.11-cp37-cp37m-linux_x86_64.whl (152.9 MB)\n",
            "Requirement already satisfied: cloud-tpu-client==0.10 in /usr/local/lib/python3.7/dist-packages (0.10)\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (1.8.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0) (4.2.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.1)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.31.5)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.35.0)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.15.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.17.4)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (57.4.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.17.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (21.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.56.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2022.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.2.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install tokenizers\n",
        "\n",
        "!pip install --force-reinstall git+https://github.com/xiaoyufan/nbme.git\n",
        "\n",
        "!pip install cloud-tpu-client==0.10 torch==1.11.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.11-cp37-cp37m-linux_x86_64.whl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from nbme_utils import scoring\n",
        "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "metadata": {
        "id": "8yvdXJKZFje_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Device"
      ],
      "metadata": {
        "id": "zGguS3V2OtkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "if Config.device == 'tpu':\n",
        "  assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'\n",
        "\n",
        "  import torch_xla\n",
        "  import torch_xla.core.xla_model as xm\n",
        "\n",
        "  device = xm.xla_device()\n",
        "\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6eZ8oYTOuUU",
        "outputId": "98c80cf0-fd9c-4406-e5ca-1450b01700b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:TPU has started up successfully with version pytorch-1.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer"
      ],
      "metadata": {
        "id": "PWSc9tvyig71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(Config.model)\n",
        "tokenizer.save_pretrained(f'{Config.output_dir}/tokenizer')"
      ],
      "metadata": {
        "id": "1Pwdt6Qaij_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ],
      "metadata": {
        "id": "CJU893wUh3mT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining Dataset"
      ],
      "metadata": {
        "id": "e35rBE3XjzYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(f'{Config.input_dir}/train.csv')\n",
        "valid = pd.read_csv(f'{Config.input_dir}/validate.csv')\n",
        "train.shape, valid.shape"
      ],
      "metadata": {
        "id": "dD7OvlwAh4wO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if Config.mode == 'dev':\n",
        "  train = train.sample(n=800, random_state=0).reset_index(drop=True)\n",
        "  valid = valid.sample(n=200, random_state=0).reset_index(drop=True)\n",
        "train.shape, valid.shape"
      ],
      "metadata": {
        "id": "xdAsvHtDiNw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "id": "kHFyvx81nxVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_labels(encoded):\n",
        "  labels = torch.zeros(len(encoded['input_ids']))\n",
        "\n",
        "  for idx, (seq_id, offsets) in enumerate(zip(encoded[\"sequence_ids\"], encoded[\"offset_mapping\"])):\n",
        "    if not seq_id:\n",
        "      labels[idx] = -1\n",
        "      continue\n",
        "\n",
        "    \n",
        "\n",
        "  return labels\n",
        "\n",
        "class NBMEDataset(Dataset):\n",
        "  def __init__(self, data: pd.DataFrame, tokenizer: AutoTokenizer, config: Config):\n",
        "    self.data = data\n",
        "    self.tokenizer = tokenizer\n",
        "    self.config = config\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx: int):\n",
        "    sample = self.data.iloc[idx]\n",
        "\n",
        "    encoded = self.tokenizer(\n",
        "      sample['pn_history'],\n",
        "      sample['feature_text'],\n",
        "      # TODO: Compute max length of sequences\n",
        "      max_length=self.config.sequence_max_length,\n",
        "      padding='max_length',\n",
        "      return_offsets_mapping=True,\n",
        "    )\n",
        "\n",
        "    y_true = generate_labels(encoded)\n",
        "\n",
        "    x = encoded.copy()\n",
        "    del x['offset_mapping']\n",
        "    x = {k: torch.tensor(v, dtype=torch.long) for k, v in x.items()}\n",
        "\n",
        "    return x, y_true"
      ],
      "metadata": {
        "id": "Gv_EALppj4VC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = NBMEDataset(train, tokenizer, Config)\n",
        "valid_dataset = NBMEDataset(valid, tokenizer, Config)"
      ],
      "metadata": {
        "id": "zAGgrY6H2Sq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loader"
      ],
      "metadata": {
        "id": "kaqWeZS0j1Dm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=Config.batch_size,\n",
        "    shuffle=True,)\n",
        "valid_loader = DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size=Config.batch_size,\n",
        "    shuffle=False,)"
      ],
      "metadata": {
        "id": "cX7NqYW0oWJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y_true = next(iter(train_loader))"
      ],
      "metadata": {
        "id": "jdWHYq692A0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "PzznXRtpOYaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NBMEDebertaBaseline(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    config = AutoConfig.from_pretrained(Config.model, output_hidden_states=True)\n",
        "    self.model = AutoModel.from_pretrained(Config.model, config=config)\n",
        "\n",
        "    self.fc = nn.Linear(config.hidden_size, 1)\n",
        "\n",
        "  def forward(self, data):\n",
        "    last_out = self.model(**data)[0]\n",
        "    logits = self.fc(last_out)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "6XiPIjKPOZeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NBMEDebertaBaseline()"
      ],
      "metadata": {
        "id": "WqQxsOTfSymm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "Yg0_Tq_qSlKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "j3_PD6hISmJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "3hycpJFVg0n9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iJnrh4_3g2Nw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}